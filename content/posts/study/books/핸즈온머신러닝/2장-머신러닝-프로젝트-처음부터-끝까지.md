---
title: "2장 머신러닝 프로젝트 처음부터 끝까지"
date: 2024-01-28T10:57:16+09:00
last_modified_at: 2024-01-28T10:57:16+09:00
draft: false 
categories: ["머신러닝"]
tags: ["핸즈온머신러닝", "스터디"]
image: 
---

진행할 주요 단계 
* 큰 그림 보기 
* 데이터 구하기 
* 데이터로부터 인사이트를 얻기 위해 탐색하고 시각화 
* 머신러닝 알고리즘을 위해 데이터 준비 
* 모델을 선택하고 훈련 
* 모델을 미세 튜닝 
* 솔루션을 제시 
* 시스템 론칭, 모니터링, 유지보수 

# 2.1 실제 데이터로 작업하기 
* 유명한 공개 데이터 
  * https://openml.org 
  * https://kaggle.com/datasets
  * https://paperswithcode.com/datasets 
  * https://archive.ics.uci.edu/ml
  * https://registry.opendata.aws 
  * https://tensorflow.org/datasets
* 메타포털 
  * https://dataportals.org
  * https://opendatamonitor.eu
* 공개 데이터 저장소 안내 페이지 
  * https://homl.info/9
  * https://homl.info/10
  * https://www.reddit.com/r/datasets

# 2.2 큰 그림 보기 
* 캘리포니아 인구 조사 데이터를 사용해 캘리포니아의 주택 가격 모델 만들고 다른 측정 데이터가 주어졌을 때 구역의 중간 주택 가격을 예측하기 
 
> 첫번째 할일은 머신러닝 프로젝트 체크리스트를 준비하는 것 
 
## 2.2.1 문제 정의 
* 비즈니스의 목적이 정확히 무엇인가? 
  * 투자할 가치가 있는 지역을 결정할 때 사용할 모델 개발  
    * 모델의 출력(구역의 중간 주택 가격에 대한 예측)이 여러 가지 다른 신호와 함께 다른 머신러닝 시스템에 입력으로 사용됨. 

> 파이프라인 
> * 데이터 처리 컴포넌트들이 연속되어 있는 것 
> * 컴포넌트들은 비동기적으로 작동하면서 많은 데이터를 추출해 처리하고 결과를 다른 데이터 저장소를 보냄. 일정 시간이 지난 후 파이프라인의 다음 컴포넌트가 그 데이터를 추출해 자신의 출력 결과를 만듬. 
> * 각 컴포넌트는 완전히 독립적으로 컴포넌트 사이의 인터페이스는 데이터 저장소 뿐 

* 현재 솔루션은 어떻게 구성되어 있는가? 
  * 현재 상황은 문제 해결 방법에 관한 정보를 제공할 뿐만 아니라 참고 성능으로도 사용할 수 있음. 

* 모델 훈련에 어떤 지도 방식을 사용할 것인가? 
  * 레이블된 훈련 샘플 => 지도 학습 
  * 모델이 값을 예측해야 함 => 회귀 문제 
  * 예측에 사용할 특성이 여러 개 => 다중 회귀 문제 
  * 시스템에 들어오는 데이터에 연속적인 흐름이 없고, 빠르게 변하는 데이터에 적응하지 않아도 되고, 데이터가 메모리에 들어갈 만큼 충분히 작음 => 배치 학습 

> 데이터가 매우 크면 맵리듀스를 사용해서 배치 학습을 여러 서버로 분할하거나 온라인 학습 기법 사용 가능 

## 2.2.2 성능 측정 지표 선택 
* 회귀 문제의 전형적인 성능 지표 
  * 평균 제곱근 오차(root mean square error, RMSE)
    * ${RMSE \left( \mathbf{X}, h \right)}$: 가설 ${h}$를 사용하여 일련의 샘플을 평가하는 비용 함수.
    * ${RMSE \left( \mathbf{X}, h \right) = \sqrt{\frac{1}{m} \sum\limits_{i=1}^m \left(h\left(\mathbf{x}^\left(i \right) \right)-y^\left(i \right) \right)^2}}$
      * ${m}$: RMSE를 측정할 데이터셋에 있는 샘플 수 
      * ${\mathbf{x^\left(i \right)}}$: 데이터셋에 있는 i번째 샘플(레이블 제외)의 전체 특성값의 벡터
      * ${\mathbf{y^\left(i \right)}}$: 해당 레이블(해당 샘플의 기대 출력값)
        * 예
          * ${\mathbf{x^\left(1 \right)} = \begin{pmatrix} -118.29\\\33.91\\\1,416\\\38,372 \end{pmatrix}}$ 
        * ${y^\left(1 \right) = 156,400}$
      * ${\mathbf{X}}$: 데이터셋에 있는 모든 샘플의 모든 특성값(레이블은 제외)을 포함하는 행렬. 샘플 하나가 하나의 행이어서 i번째 행은 ${\mathbf{x}^\left(i \right)}$ 의 전치와 같고 ${\left(\mathbf{x}^\left(i \right)\right)^T}$
        * 예 
        * ${\mathbf{X} = \begin{pmatrix} \left(\mathbf{x}^\left(1 \right)\right)^T\\\ \left(\mathbf{x}^\left(2 \right)\right)^T\\\ \vdots \\\ \left(\mathbf{x}^\left(1999 \right)\right)^T \\\ \left(\mathbf{x}^\left(2000 \right)\right)^T \end{pmatrix} = \begin{pmatrix} -118.29 & 33.91 & 1,416 & 38,372 \\\ . & . & . & . \\\ . & . & . & . \\\ \end{pmatrix}}$
      * ${h}$: 시스템의 예측 함수이며 가설(hypothesis)라고도 함. 시스템이 하나의 샘플 특성 벡터 ${\mathbf{x}^\left(i \right)}$ 를 받으면 그 샘플에 대한 예측값 ${\hat{y^\left(i \right)}=h\left(\mathbf{x}^\left(i \right) \right)}$ 을 출력 
      * 첫번째 구역의 중간 주택 가격을 ${158,400}$이라고 예측 시 ${\hat{y^\left(i \right)}=h\left(\mathbf{x}^\left(i \right) \right) = 158,400}$. 예측 오차는 ${\hat{y^\left(1 \right)} - y^\left(1 \right) = 2,000}$
  * 평균 절대 오차(MAE, 평균 절대 편차라고도 함)
    * 이상치로 보이는 구역이 많은 경우 사용 
    * ${MAE\left(\mathbf{X},h \right)=\frac{1}{m}\sum\limits_{i=1}^m\lvert h\left(\mathbf{x}^\left(i \right) \right) - y^\left(i \right) \rvert}$
  * RMSE와 MAE 모두 예측값의 벡터와 타깃값의 벡터 사이의 거리를 재는 방법임 
  * 거리측정에는 여러가지 방법이 있음(노름, norm)
    * 유클리드 노름(Euclidean norm): 제곱항을 합한 것의 제곱근(RMSE)
      * 친숙한 거리 개념
    * 맨해튼 노름(Manhattan norm): 절댓값의 합을 계산 
      * 도시의 구획이 직각으로 나뉘어 있을 때 도시의 두 지점 사이를 거리를 측정
    * 일반적으로 원소가 ${n}$ 개인 벡터 ${\mathbf{v}}$ 의 ${l_k}$ 노름은 ${\lVert \mathbf{v} \rVert _k = \left(\lvert v_0 \rvert^k + \lvert v_1 \rvert^k + \dots + \lvert v_n \rvert^k \right)^\frac{1}{k}}$. ${l_0}$ 은 벡터에 있는 0이 아닌 원소의 수이고, ${\infty}$는 벡터에서 가장 큰 절댓값 
    * norm의 지수가 클수록 큰 값의 원소에 치우치며 작은 값은 무시됨
      * 그래서 RMSE가 MAE보다 조금 더 이상치에 민감함. 
      * 이상치가 매우 드물면 RMSE가 잘 맞아 일반적으로 널리 사용함 
> 표기법 
> * 스칼라값이나 함수: 기울어진 소문자(${m, y^\left(i \right), h}$)
> * 벡터: 굵은 소문자(${\mathbf{x}^\left(i \right)}$) 
> * 행렬: 굵은 대문자(${\mathbf{X}})$ 

## 2.2.3 가정 검사 
* 지금까지 만든 가정을 나열하고 검사해보기 

# 2.3 데이터 가져오기  
## 2.3.1 구글 코랩을 사용하여 예제코드 실행하기 
* 잘하면 됨 

## 2.3.2 코드와 데이터 저장하기 
* 구글 드라이브를 마운트해서 사용할 수 있음. 

## 2.3.3 대화식 환경의 편리함과 위험 

## 2.3.4 책의 코드와 노트북의 코드 

## 2.3.5 데이터 다운로드 

## 2.3.6 데이터 구조 훑어보기 
> 데이터를 더 깊게 들여다보기 전에 테스트 세트를 따로 떼어놓고 들여다보면 안됨 

## 2.3.7 테스트 세트 만들기 
* 우리 뇌는 매우 과대적합되기 쉬운 패턴 감지 시스템 
  * 데이터 스누핑 
    * 테스트 세트를 먼저 보면 어떤 패턴에 속아 특정 머신러닝 모델을 선택할 수 있음 
    * 일반화 오차를 추정 시 매우 낙관적인 추정이 되어 기대한 성능이 나오지 않음 
* 계층적 샘플링 
* 종종 등한시 되지만 테스트 세트 생성은 머신러닝 프로젝트에서 아주 중요한 부분 

# 2.4 데이터 이해를 위한 탐색과 시각화 
## 2.4.1 지리적 데이터 시각화하기 
## 2.4.2 상관관계 조사하기 
* 모든 특성 간의 표준 상관계수(standard correlation coefficient, 피어슨의 r) 구하기
  * 피어슨 상관계수 
    * "전체 편차" 내에서 '예측치와 평균 간의 차이'가 차지하는 비율
  * 상관관계의 범위는 -1부터 1까지. 1에 가까우면 강한 양의 상관관계를 가진다는 뜻. 0에 가까우면 선형적인 상관관계가 없다는 뜻. -1에 가까우면 강한 음의 상관관계를 가진다는 뜻 
    * 절대값이 1에 가까운 상관계수: 매우 확고한 상관. 대부분의 상식(예. 다리가 길면 키도 커진다.)
    * 절대값이 0.5 정도의 상관계수: 상관관계가 있다고 통게적으로 지지받을 수 있는 수준 
    * 절대값이 0.2 정도의 상관계수: 미약한 상관. 상관관계가 있다고 장담할 수 없으며, 연구가 더 필요한 수준이나 사회과학에서는 상관관계가 강력한 것으로 봄.
    * 0에 가까운 상관계수: 대부분의 경우, 상관관계가 없다고 봄 

> 상관계수는 선형적인 상관관계만 측정(x가 증가하면 y는 증가 또는 감소하는 경우). 그래서 비선형적인 관계는 잡을 수 없음.(x가 0에 가까워지면 y가 증가하는 경우)  
  
## 2.4.3 특성 조합으로 실험하기 
* 머신러닝 알고리즘용 데이터를 준비하기 전에 마지막으로 특성을 여러가지로 조합해보기 
  * 예를 들어 특정 구역의 방 개수는 가구 수를 모른다면 그다지 유용하지 않음.
  * 여러 가지 특성을 만들어서 추가. 
* 빠르게 시작해서 인사이트를 얻는 것이 합리적임 
* 프로토타입을 만들고 실행한 후 그 결과를 분석해서 더 많은 인사이트를 얻고 다시 이 탐색 단계로 돌아옴 

# 2.5 머신러닝 알고리즘을 위한 데이터 준비 
* 머신러닝 알고리즘을 위한 데이터 준비는 자동화할 것
  * 어떤 데이터셋에 대해서도 데이터 변환을 손쉽게 반복 가능 
  * 향후 프로젝트에 재사용 가능한 변환 라이브러리를 점진적으로 구축 가능 
  * 실제 시스템에서 알고리즘에 새 데이터를 주입하기 전에 이 함수를 사용해 변환 
  * 여러 가지 데이터 변환을 쉽게 시도해볼 수 있고 어떤 조합이 가장 좋은지 확인하는데 편리 

## 2.5.1 데이터 정제 
* 누락된 특성을 정제하기 
  * 해당 구역을 제거 
  * 전체 특성을 삭제 
  * 누락된 값을 어떤 값으로 채움. 대체(imputation)

> 사이킷런의 설계 철학 
> * 일관성: 모든 객체는 일관되고 단순한 인터페이스를 공유 
>   * 추정기: 데이터셋을 기반으로 일련의 모델 파라미터들을 추정하는 객체  
>   * 변환기: 데이터셋을 변환하는 추정기 
>   * 예측기: 일부 추정기는 주어진 데이터셋에 대해 예측을 만들 수 있음  
> * 검사 가능: 모든 추정기의 하이퍼파라미터는 공개 인스턴스 변수로 직접 접근할 수 있고, 모든 추정기의 학습된 모델 파라미터도 접미사로 밑줄을 분여서 공개 인스턴스 변수로 제공됨  
> * 클라스 남용 방지: 데이터셋을 별도의 클래스가 아니라 넘파이 배열이나 사이파이 희소 행렬로 표현. 하이퍼파라미터는 보통 파이썬 문자열이나 숫자 
> * 조합성: 기존의 구성 요소를 최대한 재사용.  
> * 합리적인 기본값: 일단 돌아가는 기본 시스템을 빠르게 만들 수 있도록 대부분의 매개변수에 합리적인 기본값을 지정 

## 2.5.2 텍스트와 범주형 데이터 다루기 

## 2.5.3 특성 스케일과 변환 
* 특성 스케일링 
  * 몇 가지를 제외하고 머신러닝 알고리즘은 입력된 숫자 특성들의 스케일이 많이 다르면 제대로 작동하지 않음 
  * 모든 특성의 범위를 같게 만들어주는 방법으로 min-max 스케일링과 표준화가 널리 사용됨 

> 모든 추정기와 마찬가지로 스케일링은 훈련 데이터로만 수행해야 됨. 훈련 세트 이외의 어떤 것에도 fit()이나 fit_transform()메서드를 사용하면 안됨. 

* min-max 스케일링 
  * 각 특성에 대해서 0~1 범위에 들도록 값을 이동하고 스케일을 조정 
* 표준화 
  * 평균을 뺀후 표준 편차로 나눔
  * 특정 범위로 값을 제한하지 않음. 
  * 이상치에 영향을 덜 받음.

## 2.5.4 사용자 정의 변환기 

## 2.5.5 변환 파이프라인 
* 변환 단계는 올바른 순서대로 실행되어야 함 
* 파이프라인이 할일 
  * 대부분의 머신러닝 알고리즘은 누락된 값을 기대하지 않기 때문에 수치형 특성의 경우 누락된 값을 중간값으로 대체. 범주형 특성의 경우 누락된 값을 가장 많이 등장하는 카테고리로 바꿈 
  * 대부분의 머신러닝 알고리즘은 수치 입력만 받기 때문에 범주형 특성을 원-핫 인코딩 
  * 비율 특성인 bedrooms_ratio, rooms_per_house, people_per_house를 계산하여 추가 
  * 몇 가지 클러스터 유사도 특성을 추가. 위도와 경도보다 모델에 더 유용할 가능성이 높음 
  * 대부분의 모델은 균등 분포나 가우스 분포에 가까운 특성을 선호하기 때문에 꼬리가 두꺼운 분포를 띠는 특성을 로그값으로 바꿈 
  * 대부분의 머신러닝 알고리즘은 모든 특성이 대체로 동일한 스케일을 가질 때 잘 작동하므로 모든 수치 특성을 표준화함 

# 2.6 모델 선택과 훈련 
* 지금까지 한 일 
  * 문제를 정의한 후 데이터를 읽고 탐색. 
  * 훈련 세트와 테스트 세트로 나눈 다음, 머신러닝 알고리즘에 주입할 데이터를 자동으로 정제하는 전처리 파이프라인을 작성.
* 이제 머신러닝 모델을 선택하고 훈련할 차례 
  
## 2.6.1 훈련 세트에서 훈련하고 평가하기 
* 훈련 및 평가 순서 
  * 훈련: {model}.fit으로 학습 
  * 예측: {model}.predict(input)
  * 성능측정: mean_squared_error()의 squared를 False로 지정. RMSE 계산

## 2.6.2 교차 검증으로 평가하기 
* train_test_split 함수를 사용해 훈련 세트를 더 작은 훈련 세트와 검증 세트로 나눈 다음, 더 작은 훈련 세트에서 무델을 훈련시키고 검증 세트로 모델을 평가
* k-폴드 교차 검증 
  * 훈련 세트를 폴드라 불리는 중복되지 않은 10개의 서브셋으로 랜덤 분할 
  * 결정 트리 모델을 10번 훈련하고 평가하는데, 매번 다른 폴드를 선택해 평가에 사용 
  * 나머지 9개 폴드는 훈련에 사용
  * 10개의 평가 점수가 담긴 배열이 결과가 됨 
* 훈련오차가 작고 검증오차가 높으면 과대적합 
* 결정 트리 모델, 선형 회귀 모델, 랜덤 포레스트 모델 세 개를 테스트 
* 랜덤 포레스트 모델 
  * 특성을 랜덤으로 선택해서 많은 결정 트리를 만들고 예측의 평균을 구하는 방식으로 작동 
  * 앙상블: 서로 다른 모델들로 구성된 모델
* 과대적합을 해결하는 방법 
  * 모델을 단순화 
  * 제한(규제)
  * 더 많은 훈련데이터 수집 
* 하이퍼파라미터 조정에 너무 많은 시간을 들이지 말고 여러 종류의 머신러닝 알고리즘에서 다양한 모델을 시도해 2~5개 정도의 모델을 선정하는 것을 목표로 해야 함 

# 2.7 모델 미세 튜닝 
* 가능성 있는 모델을 추렸다면 모델을 미세 튜닝할 것 

## 2.7.1 그리드 서치 
* 가장 단순한 방법은 만족할만한 하이퍼파라미터 조합을 찾을 때까지 수동으로 하이퍼파라미터를 조정
  * 지루하고 어려움 
* 사이킷런의 GridSearchCV
  * 교차 검증을 사용해 가능한 모든 하이퍼파라미터 조합을 평가 
  * 비교적 적은 수의 조합을 탐구할 때 좋음 

## 2.7.2 랜덤 서치 
* 사이킷런의 RandomizedSearchCV 
  * 하이퍼파라미터 탐색 공간이 커지면 선호됨 
  * 가능한 모든 조합을 시도하는 대신 각 반복마다 하이퍼파라미터에 임의의 수를 대입하여 지정한 횟수만큼 평가 
  * 장점 
    * 하이퍼파라미터 값이 연속적이면 랜덤 서치를 1000번 실행했을 때 각 하이퍼파라미터마다 1000개의 다른 값을 탐색. 반면에 하이퍼파라미터에 대해 나열한 몇 개의 값만을 탐색 
    * 어떤 하이퍼파라미터가 성능 면에서 큰 차이를 만들지 못하지만 아직 이 사실을 모른다고 가정하면 10개의 가능한 값이 있을 때 이를 그리드 서치에 추가하면 훈련이 10배 더 오래 걸림. 하지만 이 하이퍼파라미터를 랜덤 서치에 추가하면 탐색 시간이 더 늘어나지 않음 
    * 6개의 하이퍼파라미터에 대해 각각 10개의 값을 탐색한다면 그리드 서치는 백만 번 모델을 훈련해야 하지만 랜덤 서치는 지정한 반복 횟수만큼 실행할 수 있음 

## 2.7.3 앙상블 방법 
* 최상의 모델을 연결하는 것 
* 모델의 그룹이 최상의 단일 모델보다 더 나은 성능을 발휘할 때가 많음 
  
## 2.7.4 최상의 모델과 오차 분석 
* 최상의 모델을 분석하면 문제에 대한 좋은 인사이트를 얻는 경우가 많음 
* 시스템이 특정한 오차를 만들었다면 왜 그런 문제가 생겼는지 이해해야 함 
  * 추가특성을 포함시키거나, 불필요한 특성을 제거하거나, 이상치를 제외하는 등 해결 방법을 찾아야 함 

## 2.7.5 테스트 세트로 시스템 평가하기 
* 모델을 튜닝하면 만족할만한 모델을 얻게 됨. 
* 테스트 세트에서 최종 모델을 평가 

# 2.8 론칭, 모니터링, 시스템 유지 보수 
* 전용 웹 서비스로 모델을 감싸기 
  * 주 애플리케이션을 건드리지 않고 모델을 새 버전으로 업그레이드하기 쉬움 
  * 로드 밸런싱 가능 
  * 웹 애플리케이션을 파이썬이 아닌 다른 언어로도 작성 가능 
* 구글 버텍스 AI 
* 배포 이후에도 모니터링 필요. 
  * 모델의 실전 성능을 모니터링 필요. 
  * 모델이 실패했을 때 무엇을 할지 정의하고 어떻게 대비할 지 관련 프로세스를 모두 준비해야 함. 
* 데이터가 계속 변화하면 데이터셋을 업데이트하고 모델을 정기적으로 다시 훈련해야 하고 자동화 필요. 
  * 정기적으로 새로운 데이터를 수집하고 레이블을 담 
  * 모델을 훈련하고 하이퍼파라미터를 자동으로 미세 튜닝하는 스크립트를 작성 
  * 업데이트된 테스트 세트에서 새로운 모델과 이전 모델을 평가하는 스크립트를 하나 더 작성 
* 모델의 입력 데이터 품질 평가
* 만든 모든 모델을 백업해야 함.
