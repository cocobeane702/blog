---
title: "1장. 한눈에 보는 머신러닝"
date: 2024-01-27T22:36:51+09:00
last_modified_at: 2024-01-27T22:36:51+09:00
draft: false 
categories: 
tags:
image: 
---

# 1.1 머신러닝이란? 
머신러닝은 데이터에서 학습하도록 컴퓨터를 프로그래밍하는 과학(또는 예술)

> 머신러닝은 명시적인 프로그래밍 없이 컴퓨타가 학습하는 능력을 갖추게 하는 연구 분야다.
> - 아서 새뮤얼(Arthur Samuel), 1959

> 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다. 
> - 톰 미첼(Tom Mitchell), 1997

* 훈련세트(training set): 시스템이 학습하는 데 사용하는 샘플 
* 훈련사례(training instance, sample): 각각의 훈련데이터 
* 모델(model): 머신러닝 시스템에서 학습하고 예측을 만드는 부분
  * 예로는 신경망, 랜덤 포레스트가 있음 
  
스팸필터를 이 용어에 비추어 보면 
- 작업 T: 새로운 메일이 스팸인지 구분 
- 경험 E: 훈련 데이터(training data)
- 성능 측정 P: 직접 정의. 예를 들면 정확히 분류된 메일의 비율 
- 성능 측정은 정확도(accuracy)로 부르고 분류 작업에 자주 사용

# 1.2 왜 머신러닝을 사용하나요? 
* 스팸필터를 전통적인 기법으로 만들면? 
  * 문제가 어려워서 규칙이 점점 길고 복잡해지므로 유지 보수가 어려워짐.
* 스팸필터를 머신러닝 기법에 기반을 둔다면?
  * 일반 메일에 비해 스팸에 자주 나타나는 패턴을 감지하여 어떤 단어와 구절이 스팸 메일을 판단하는 데 좋은 기준인지 자동으로 학습 
  * 프로그램이 훨씬 짧아지고 유지 보수하기 쉬우며 대부분 정확도가 더 높음 
* 머신러닝이 유용한 분야 
  * 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제 
    * 머신러닝 모델이 코드를 간단하게 만들고 전통적인 방법보다 더 잘 수행할 수 있음 
  * 전통적인 방식으로는 해결 방법이 없는 복잡한 문제 
    * 가장 뛰어난 머신러닝 기법으로 해결방법을 찾을 수 있음 
  * 유동적인 환경
    * 머신러닝 시스템은 새로운 데이터로 쉽게 재훈련할 수 있어 항상 최신 상태를 유지함 
  * 복잡한 문제와 대량의 데이터에서 인사이트 얻기 

# 1.3 애플리케이션 사례 
* 생산 라인에서 제품 이미지를 분석해 자동으로 분류하기 
  * 이미지 분류 작업 
  * 일반적으로 합성곱 신경망(convolutional neural network(CNN))이나 이따금 트랜스포머(Transformer)를 사용하여 수행
* 뇌를 스캔하여 종양진단하기 
  * 시맨틱 분할 작업 
  * 일반적으로 CNN이나 트랜스포머를 사용해 이미지의 각 픽셀을 분류 
* 자동으로 뉴스 기사 분류하기 
  * 자연어 처리(natural language processing(NLP)) 작업. 텍스트 분류 작업
  * 순환 신경망(recurrent neural network(RNN)), CNN을 사용해 해결할 수 있지만 트랜스포머가 훨씬 더 잘 처리함 
* 토론 포럼에서 부정적인 코멘트를 자동으로 구분하기 
  * 텍스트 분류 작업
  * NLP 도구를 사용 
* 긴 문서를 자동으로 요약하기 
  * 텍스트 요약이라 불리는 NLP의 한 분야 
  * NLP 도구를 사용 
* 챗봇 또는 개인 비서 만들기 
  * 자연어 이해(natural language understanding(NLU))와 질문-답변 모듈을 포함해 여러 가지 NLP 컴포넌트가 필요 
* 여러 가지 성과 자료를 바탕으로 회사의 내년도 수익 예측하기 
  * 회귀 작업(regression)
  * 선형 회귀(linear regression)나 다항 회귀(polynomial regression) 모델, 회귀 서포트 벡터 머신(support vector machine), 회귀 랜덤 포레스트(random forest), 인공 신경망(artificial neural network)와 같은 회귀모델을 사용 
  * 과거 성과 데이터를 시퀀스로 고려하고 싶다면 RNN, CNN, 또는 트랜스포머를 사용
* 음성 명령에 반응하는 앱 만들기 
  * 음성 인식 작업 
  * 일반적으로 RNN, CNN, 또는 트랜스포머를 사용
* 신용카드 부정 거래 감지하기 
  * 이상치 탐지 작업 
  * 아이솔레이션 포레스트(isolation forest), 가우스 혼합(gaussian mixture) 모델이나 오토인코더(autoencoder)를 사용 
* 구매 이력을 기반으로 고객을 나누고 각 집합마다 다른 마케팅 전략을 계획하기 
  * 군집 작업 
  * k-평균(k-mean), DBSCAN 등을 사용
* 고차원의 복잡한 데이터셋을 명확하고 의미 있는 그래프로 표현하기 
  * 데이터 시각화 작업 
  * 차원 축소(dimensionality reduction)을 많이 사용 
* 과거 구매 이력을 기반으로 고객이 관심을 가질 수 있는 상품 추천하기 
  * 추천 시스템 
  * 과거 구매 이력을 인공 신경망에 주입하고 다음에 구매할 가능성이 높은 상품을 출력하는 것이 한가지 방법
* 지능형 게임 봇 만들기 
  * 보통 강화학습(reinforcement learning)으로 해결 
  * 시간이 지나면 주어진 환경에서 보상이 최대가 되는 행동을 선택하는 에이전트를 훈련하는 머신러닝의 한 분야 
  
# 1.4 머신러닝 시스템의 종류 

## 1.4.1 훈련 지도 방식 
머신러닝 시스템을 학습하는 동안의 지도 형태나 정보량에 따라 분류 가능 
- 지도 학습 
- 비지도 학습 
- 준지도 학습 
- 자기 지도 학습 
- 강화 학습 

### 지도 학습(supervised learning)
* 지도 학습에서는 알고리즘에 주입하는 훈련 데이터에 레이블(label)이라는 원하는 답이 포함됨 
* 분류(classification)는 전형적인 지도 학습 작업
* 회귀(regression) 
  * 특성(feature,주행 거리, 연식, 브랜드 등)을 사용해 중고차 가격 같은 타깃(target) 수치를 예측하는 것
  * 주어진 입력 특성으로 값을 예측 

> - 지도 학습에서 타깃과 레이블은 일반적으로 동의어로 취급됨 
> - 타깃은 회귀 작업에서 많이 사용되고 레이블은 분류 작업에서 많이 사용됨 
> - 특성은 예측 변수(predictor)나 속성(attribute)이라고도 부름 

### 비지도 학습(unsupervised learning) 
* 비지도 학습은 훈련 데이터에 레이블이 없음.
  * 시스템이 아무런 도움 없이 학습 
* 예
  * 계층 군집(hierachical clustering) 
    * 각 그룹을 더 작은 그룹으로 세분화 
  * 시각화 알고리즘 
    * 레이블이 없는 대규모의 고차원 데이터를 넣으면 도식화가 가능한 2D나 3D를 만들어줌 
  * 차원축소(dimentionality reduction) 
    * 너무 많은 정보를 잃지 않으면서 데이터를 간소화
    * 특성 추출(feature extraction)
      * 상관관계가 있는 여러 특성을 하나로 합침 
  * 이상치 탐지(outlier detection)
    * 시스템이 훈련하는 동안 대부분 정상 샘플을 보고 인식하도록 훈련 
    * 새로운 샘플을 보고 정상 데이터이지 이상치인지 판단 
    * 유사한 작업으로 특이치 탐지(novelty detection)가 있음 
  * 연관 규칙 학습(association rule learning)
    * 대량의 데이터에서 특성 간의 흥미로운 관계를 찾음 
  
### 준지도 학습(semi-supervised learning)
* 준지도 학습은 레이블된 샘플이 적은 경우 
* 대부분의 준지도 학습 알고리즘은 지도 학습과 비지도 학습의 조합으로 이루어져 있음. 

### 자기 지도 학습(self-supervised learning)
* 자기 지도 학습은 레이블이 전혀 없는 데이터셋에서 레이블이 완전히 부여된 데이터셋을 생성하는 것 

> 한 작업에서 다른 작업으로 지식을 전달하는 것을 전이 학습(transfer learning)이라고 부름. 
> 오늘날 머신러닝 분야, 특히 심층 신경망(deep neural network)를 사용할 때 가장 중요한 기술.

### 강화 학습 
* 학습하는 시스템을 에이전트(agent)라고 부르며 환경(environment)를 관찰해서 행동(action)을 실행하고 그 결과로 보상(reward)를 받음. 
* 시간이 지나면서 가장 큰 보상을 얻기 위해 정책(policy)이라고 부르는 최상의 전략을 스스로 학습 
* 정책은 주어진 상황에서 에이전트가 어떤 행동을 선택해야 할지 정의함.

## 1.4.2 배치 학습과 온라인 학습 
입력 데이터의 스트림으로부터 점진적으로 학습할 수 있는지 여부에 따른 분류 

### 배치 학습 
* 배치학습에서는 시스템이 점진적으로 학습할 수 없고 가용한 데이터를 모두 사용해 훈련함 
* 시간과 자원을 많이 소모하므로 오프라인에서 수행됨 
* 오프라인 학습 
  * 시스템을 훈련시킨 다음 제품 시스템에 적용하면 더 이상의 학습 없이 실행됨 
  * 학습한 것을 적용만 함
* 모델 부패(model rot) 또는 데이터 드리프트(data drift)
  * 모델의 성능은 시간이 지남에 따라 천천히 감소 
  * 세상은 계속 진화하는데 모델은 바뀌지 않고 그대로이기 때문 
  * 이를 해결하기 위해서는 최신 데이터에서 모델을 정기적으로 재훈련함. 

> 고양이, 강아지 사진 분류처럼 재훈련 안해도 될 것 같은 모델도 정기적으로 훈련해야 할 수 있음. 왜? 카메라가 계속 바뀌고 발전하고 있기 때문.

* 배치 학습 시스템은 새로운 데이터를 학습하기 위해 전체 데이터를 사용해서 시스템의 새로운 버전을 처음부터 다시 훈련해야 함. 
* 보통 24시간마다 또는 매주 시스템을 훈련시킴. 시스템이 빠르게 변하는 데이터에 적응해야 한다면 더 능동적인 방법이 필요. 
* 데이터셋이 크기 때문에 많은 컴퓨팅 자원이 필요
* 자원이 제한된 시스템에서는 심각한 문제가 있을 수 있음. 

### 온라인 학습 
* 온라인 학습에서는 데이터를 순차적으로 한 개씩 또는 미니배치라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킴 
* 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습할 수 있음 
* 극도로 빠른 변화에 적응해야 하는 시스템에 적합 
* 컴퓨팅 자원이 제한된 경우에도 좋은 선택 
* 컴퓨터 한 대의 메인 메모리에 들어갈 수 없는 아주 큰 데이터셋에서 모델을 훈련할 수도 있음(외부 메모리 학습(out-of-core learning))

> 외부 메모리 학습은 보통 오프라인으로 실행됨. 그래서 온라인 학습이란 이름이 혼란을 줄 수 있음. 점진적 학습이라고 생각할 것 

* 학습률(learning rate)
  * 온라인 학습 시스템에서 중요한 파라미터는 변화하는 데이터에 얼마나 빠르게 적응할 것인지
  * 학습률을 높게 하면 시스템이 데이터에 빠르게 적응하지만 예전 데이터를 금방 잊어버림 
  * 학습률이 낮으면 시스템의 관성이 더 커져서 더 느리게 학습됨. 
* 문제점 
  * 시스템에 나쁜 데이터가 주입되었을 때 시스템 성능이 감소 
  * 데이터 품질과 학습률에 따라 빠르게 감소할 수도 있음 
  * 버그나 시스템을 속이려는 행위로 인해 나쁜 데이터가 들어올 수 있음. 
  * 이런 위험을 줄이려면 시스템을 면밀히 모니터링하고 성능 감소가 감지되면 즉각 학습을 중지 시키고 가능하면 이전 운영 상태로 되돌림. 
  * 이상치 탐치 알고리즘 등을 사용해서 비정상 데이터를 잡아낼 수 있음 

## 1.4.3 사례 기반 학습과 모델 기반 학습 
어떻게 일반화(generalization)되는가에 따라 머신러닝 시스템을 분류
진짜 목표는 훈련 데이터에서 높은 성능을 내는 모델이 아니라 새로운 샘플로 잘 작동하는 모델.

### 사례 기반 학습(instance-based learning) 
* 사례 기반 학습은 시스템이 훈련 샘플을 기억해서 학습함
* 유사도 측정을 사용해 새로운 데이터와 학습한 샘플을 비교하는 식으로 일반화함 

### 모델 기반 학습 
* 모델 기반 학습은 샘플의 모델을 만들어 예측에 사용하는 것 
  
> '모델'이라는 단어는 다음을 의미할 수 있음 
>  - 모델의 종류(예. 선형회귀)
>  - 완전히 정의된 모델 구조(예. 하나의 입력과 하나의 출력을 가진 선형 회귀)
>  - 예측에 사용하기 위해 준비된 훈련된 최종 모델(예. ${\theta_0=3.75}$ 와 ${\theta_1=6.78\times{10^{-5}}}$ 이고 입력 하나와 출력 하나를 가진 선형 회귀)

* 전형적인 머신러닝 프로젝트 
  * 데이터를 분석 
  * 모델을 선택 
  * 훈련 데이터로 모델을 훈련(학습 알고리즘이 비용 함수를 최소화하는 모델 파라미터를 찾음) 
  * 잘 일반화되기를 기대하면서 새로운 데이터에 모델을 적용해 예측을 만듬(이를 추론이라고 함)

# 1.5 머신러닝의 주요 도전 과제 
머신러닝은 모델을 선택해서 어떤 데이터에 훈련시키는 것이 주요 작업이기 때문에 문제가 될 수 있는 것은 '나쁜 모델'과 '나쁜 데이터'

## 1.5.1 충분하지 않은 양의 훈련 데이터 
대부분의 머신러닝 알고리즘이 잘 작동하려면 데이터가 많아야 함 
아주 간단한 문제여도 매우 많은 데이터가 필요함.

> 믿기 힘든 데이터의 효과 
> - 충분한 데이터가 주어지면 아주 간단한 모델을 포함하여 여러 다른 머신러닝 알고리즘이 복잡한 자연어 중의성 해소 문제를 거의 비슷하게 처리한다. 
> - 시간과 돈을 알고리즘 개발에 쓰는 것과 말뭉치 개발에 쓰는 것 사이의 트레이드오프를 다시 생각해봐야 함 
> - 복잡한 문제의 경우 알고리즘보다 데이터가 더 중요할 수 있음. 

## 1.5.2 대표성 없는 훈련 데이터 
* 일반화가 잘되려면 훈련 데이터가 일반화하고 싶은 새로운 사례를 잘 대표하는 것이 중요
* 일반화하려는 사례들을 대표하는 훈련 세트를 사용하는 것이 중요하지만 어려울 때가 많음 
* 샘플링 잡음(sampling noise)
  * 샘플이 작으면 우연에 의한 대표성 없는 데이터
* 샘플링 편향(sampling bias)
  * 매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 띠지 못함

> 유명한 샘플링 편향 사례 
> * 랜던과 루스벨트가 경쟁한 1936년 미국 대통령 선거에서 The Literary Digest 잡지사가 천만 명에게 우편물을 보내 수쟁한 대규모 여론 조사 
> * 240만명의 응답을 받았고, 랜던이 선거에서 57%의 득표율을 얻을 것이라고 높은 신뢰도로 예측 
> * 하지만 루스벨트가 62%의 득표율로 당선 
> * 문제는 샘플링 방법 
>   * 여론 조사용 주소를 얻기 위해 전화번호부, 자사의 구독자 명부, 클럽 회원 명부 등을 사용. 이런 명부는 모두 공화당에 투표할 가능성이 높은 부유한 계층에 편중된 경향이 있었음 
>   * 우편물 수신자 중 25% 미만의 사람이 응답했음. 정치에 관심 없는 사람, The Literary Digest를 싫어하는 사람과 다른 중요한 그룹을 제외시켜 표본을 편향되게 만듬. 이를 비응답 편향(nonresponse bias)라고 함 
  
## 1.5.3 낮은 품질의 데이터 
* 훈련 데이터가 오류, 이상치, 잡ㅇ이 많으면 머신러닝 시스템이 제대로 동작하지 못함. 
* 대부분의 데이터 과학자가 데이터 정제에 많은 시간을 쓰고 있음 

## 1.5.4 관련 없는 특성 
* garbage in, garbage out(엉터리가 들어가면 엉터리가 나옴)
* 성공적인 머신러닝 프로젝트의 핵심 요소는 훈련에 사용할 좋은 특성들을 찾는 것 
* 특성 공학(feature engineering)
  * 특성 선택(feature selection): 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택  
  * 특성 추출(feature extraction): 특성을 결합하여 더 유용한 특성을 만듬. 
  * 데이터 수집: 새로운 데이터를 수집해 새 특성을 만듬 
  
## 1.5.5 훈련 데이터 과대적합 
* 과대적합 
  * 모델이 훈련 데이터에는 너무 잘 맞지만 일반성이 떨어지는 경우 
  * 훈련 데이터의 양과 잡음에 비해 모델이 너무 복잡할 때 일어남. 
  * 해결방법 
    * 파라미터 수가 적은 모델을 선택하거나, 훈련 데이터에 있는 특성수를 줄이거나, 모델에 제약을 가하여 단순화
    * 훈련 데이터를 더 많이 모음 
    * 훈련 데이터의 잡음을 줄임 

* 규제 
  * 모델을 단순하게 하고 과대적합의 위험을 줄이기 위해 모델에 제약을 가함 

* 하이퍼파라미터 
  * 학습 알고리즘의 파라미터 
  * 학습하는 동안 적용할 규제의 양을 결정 
  * 학습 알고리즘으로부터 영향을 받지 않으며, 훈련 전에 미리 지정되고, 훈련하는 동안에 상수로 남아 있음. 
  * 하이퍼파라미터 튜닝은 매우 중요한 과정 

## 1.5.6 훈련 데이터 과소적합 
* 과소적합 
  * 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 일어남 
  * 해결방법 
    * 모델 파라미터가 더 많은 강력한 모델을 선택 
    * 학습 알고리즘에 더 좋은 특성을 제공(특성 공학)
    * 모델의 제약을 줄임(규제 하이퍼파라미터를 감소시킴) 

## 1.5.7 핵심 요약 
* 머신러닝은 명시적인 규칙을 코딩하지 않고 기계가 데이터로부터 학습하여 어떤 작업을 더 잘하도록 만드는 것 
* 머신러닝 시스템의 종류
  * 지도학습과 비지도학습 
  * 배치학습과 온라인학습 
  * 사례기반학습과 모델기반학습 
* 머신러닝 프로젝트는 훈련 세트에 데이터를 모아 학습 알고리즘에 주입. 학습 알고리즘이 모델 기반이면 훈련 세트에 모델을 맞추기 위해 모델 파라미터를 조정하고, 새로운 데이터에서도 좋은 예측을 만들거라 기대함. 학습 알고리즘이 사례 기반이면 샘플을 기억하는 것이 학습이고 유사도 측정을 사용하여 학습한 샘플과 새로운 샘플을 비교하는 식으로 새로운 샘플에 일반화함.
* 훈련세트가 너무 작거나, 대표성이 없거나, 잡음이 많고 관련없는 특성으로 오염되어 있다면 시스템이 잘 작동하지 않음. 모델이 너무 단순하거나(과소적합된 경우) 너무 복잡하지 말아야 함(과대적합된 경우)

# 1.6 테스트와 검증 
* 훈련 세트를 사용해 모델을 훈련하고 테스트 세트를 사용해 모델을 테스트함 
* 새로운 샘플에 대한 오차 비율을 일반화 오차라고 하며, 테스트 세트에서 모델을 평가함으로써 이 오차에 대한 추정값을 얻음.
* 훈련 오차가 작지만, 일반화 오차가 크다면 이는 모델이 훈련 데이터에 과대적합되었다는 뜻 

> 보통 데이터의 80%를 훈련에 사용하고 20%는 테스트용으로 떼어놓긴 하지만 데이터셋 크기에 따라 다름.

## 1.6.1 하이퍼파라미터 튜닝과 모델 선택 
* 두 모델을 비교한다면? 
  * 두 모델 모두 훈련 세트로 훈련하고 테스트 세트를 사용해 얼마나 잘 일반화되는지 비교해보면 됨.
* 일반화 오차를 테스트 세트에서 여러 번 측정하면 모델과 하이퍼파라미터가 테스트 세트에 최적화된 모델을 만드므로 오차가 높음. 따라서 모델이 새로운 데이터에 잘 작동하지 않을 수 있음 
  * 해결방법 : 홀드아웃 검증(holdout validation)
    * 훈련 세트의 일부를 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 선택. 이를 검증 세트라고 부름 
    * 검증 세트로 다양한 하이퍼파라미터 값을 가진 여러 모델을 훈련 
    * 그다음 검증 세트에서 가장 높은 성능을 내는 모델을 선택 
    * 검증을 통한 최선의 모델을 전체 훈련 세트에서 다시 훈련하여 최종 모델을 만듬 
    * 최종 모델을 테스트 세트에서 평가하여 일반화 오차를 추정
    * 이것도 검증 세트의 규모에 따른 이슈가 있음.  

## 1.6.2 데이터 불일치 
* 검증 세트와 테스트 세트는 실전에서 기대하는 데이터를 가능한 잘 대표해야 함.
* 훈련-개발 세트(train-dev set)
  * 훈련 사진의 일부를 떼어내 또다른 세트를 만듬
  * 모델을 훈련 세트에서 훈련한 다음 훈련-개발 세트에서 평가함. 
  * 모델이 훈련-개발 세트에서 잘 작동하지 않으면 훈련 세트에 과대적합된 것임 
  * 모델이 훈련-개발 세트에서 잘 작동하면 검증 세트에서 평가 진행 

> 공짜 점심 없음 이론 
> * 모델은 데이터의 간소화된 표현
> * 간소화란 새로운 샘플에서 일반적이지 않을 것 같은 불필요한 세부사항을 제거하는 것 
> * 공짜 점심 없음 이론 
>   * 데이터에 관해 완벽하게 아무런 가정도 하지 않으면 한 모델을 다른 모델보다 선호할 근거가 없음
>   * 경험하기 전에 더 잘 맞을 거라고 보장할 수 있는 모델은 없음 
>   * 어떤 모델이 최선인지 확실히 아는 유일한 방법은 모든 모델을 평가해보는 것이지만 이는 불가능.
>   * 따라서 데이터에 관해 타당한 가정을 하고 적절한 모델 몇가지만 평가함.